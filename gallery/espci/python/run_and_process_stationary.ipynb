{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the way to run the simulations and perform some basic analyses with the output H5 files. The parameters used for these simulations are those reported in the paper `Insights from the quantitative calibration of an elasto-plastic model\n",
    "from a Lennard-Jones atomic glass. Castellanos et al. Comptes Rendus. Physique, Volume 22 (2021) no. S3, pp. 135-162`. See [here](https://comptes-rendus.academie-sciences.fr/physique/item/10.5802/crphys.48.pdf).\n",
    "\n",
    "As detailed in the publication, the parameter values were obtained by optimizing these mesoscale simulation results against a set of reference molecular dynamics simulations in the stationary flow regime. The reader is referred to the publication for details.\n",
    "\n",
    "NOTE: in the publication, the results use a higher shear angle resolution. This behavior can be recovered by increasing the `n_theta` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from math import pi as pi\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import glob\n",
    "import h5py \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the simulations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the simulations using the configuration file `gallery/espci/python/stationary_state_opt.cfg` that contains the optimal parameters for simulating the stationary state of the reference molecular dynamics simulations, as reported in the publication mentioned above. \n",
    "\n",
    "MEPLS can run in parallel out of the box thanks to OpenMP, and the number of threads used is defined by the environment variable `OMP_NUM_THREADS`. We set the value to the number of available CPUs and run the executable with the mentioned config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_file = '<path-to-MEPLS-exec-file>'\n",
    "config_file = './stationary_state_opt.cfg'\n",
    "\n",
    "n_threads = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'export OMP_NUM_THREADS={n_threads} && {exec_file} -f {config_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the macroscale response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyze the macroscale response using the discrete driving events dataset located at `/AQS/driving_events` within the output H5 files hierarchy. This is the most granular data available since it is composed of individual events representing the external stress increments and drops. The former corresponds to external load increments, while the latter to drops induced by plastic deformation occurring under a fixed external strain. (see `gallery/espci/python/run_and_process_transient.ipynb` for an alternative way to produce stress-strain curves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stress_strain_meso(filenames, **kwd):\n",
    "\n",
    "    \"\"\"\n",
    "    This generator provides stress-strain curves of mesoscale data    \n",
    "    \"\"\"    \n",
    "\n",
    "    for filename in tqdm(filenames):\n",
    "        \n",
    "        try:\n",
    "            file = h5py.File(filename,'r')\n",
    "            \n",
    "            driving_ = np.array(file['/AQS/driving_events'])        \n",
    "            file.close()\n",
    "            \n",
    "            driving_df = pd.DataFrame(driving_, columns=driving_.dtype.names).set_index('index')        \n",
    "            driving_df['total_strain'] = np.cumsum(driving_df.dtotal_strain.values)\n",
    "            driving_df['gamma'] = 2. * driving_df['total_strain'] # convert epsilon to gamma\n",
    "            driving_df['ext_stress'] = np.cumsum(driving_df.dext_stress.values)\n",
    "            driving_df['pressure'] = np.cumsum(driving_df.dpressure.values)\n",
    "            \n",
    "            w = (driving_df['gamma']>=2*kwd['eps0'])&(driving_df['gamma']<2*kwd['eps1'])\n",
    "            driving_df = driving_df[w]\n",
    "            \n",
    "            driving_df['sample'] = filename\n",
    "            \n",
    "            # find stress drops carefully. Some macroscale drops are actually positive, but this is a fringe case\n",
    "            # that occurs only when some patch-scale thresholds are negative (as explained in the publication)\n",
    "            # and the system size is very small, typically smaller than what we care about\n",
    "            w = np.logical_not( (driving_df['activation_protocol']==0)&(driving_df['dext_stress']>0.) )\n",
    "            df = driving_df[['activation_protocol','dext_stress','dpressure']][w]\n",
    "            \n",
    "            # remove initial load increment (e.g., if we applied a sudden initial load such as in creep)\n",
    "            df = df.iloc[1:]\n",
    "            \n",
    "            # now we don't care about dataframe index, we reset it to get the natural one\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            D_ext_stress = list()\n",
    "            for i, group in groupby(df[['activation_protocol','dext_stress','dpressure']].values, key=lambda x: x[0]):\n",
    "                sum_ext_stress = np.sum([x[1] for x in group]) # sum of dext_stress\n",
    "                D_ext_stress.append( [i,sum_ext_stress] )\n",
    "            D_ext_stress = np.vstack(D_ext_stress)\n",
    "    \n",
    "            w_drops = D_ext_stress[:,0] == 0\n",
    "            w_incr = D_ext_stress[:,0] == 2\n",
    "            \n",
    "            # stress rises due to loading incremetns and drops due to avalanches\n",
    "            drops_ext_stress = - 1 * D_ext_stress[:,1][w_drops]\n",
    "            increments_ext_stress = D_ext_stress[:,1][w_incr]\n",
    "    \n",
    "            yield {'values': driving_df, \n",
    "                   'drops': drops_ext_stress, \n",
    "                   'increments': increments_ext_stress}\n",
    "        \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram(data, nbins=80, a=None, b=None, density=True, log=False, edges=None, filter_zeros=False):\n",
    "\n",
    "    if a is None: a = min(data)\n",
    "    if b is None: b = max(data)    \n",
    "    if edges is None: \n",
    "        if log: edges = np.logspace(np.log10(a),np.log10(b),nbins,base=10)\n",
    "        else: edges = np.linspace(a,b,nbins)\n",
    "        \n",
    "    hist, edges = np.histogram(data, edges, density=density)\n",
    "\n",
    "    edges = edges[:-1]\n",
    "    \n",
    "    if filter_zeros:\n",
    "        w = hist > 0\n",
    "        hist = hist[w]\n",
    "        edges = edges[w]\n",
    "        \n",
    "    return edges, hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load macroscale response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meso_filenames = glob.glob('./*h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = generate_stress_strain_meso(meso_filenames, eps0=0., eps1=5.)\n",
    "data = list(data_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[0]['values']\n",
    "x = df['gamma'].values\n",
    "y = df['ext_stress'].values\n",
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('stress_xy')\n",
    "\n",
    "stress_strain_df = pd.concat([d['values'] for d in data])\n",
    "x, y = make_histogram(stress_strain_df['ext_stress'].values, nbins=40, filter_zeros=True)\n",
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('stress_xy')\n",
    "plt.ylabel('PDF(stress_xy)')\n",
    "\n",
    "drops = np.hstack([d['drops'] for d in data])\n",
    "x, y = make_histogram(drops,log=True,nbins=40, filter_zeros=True)\n",
    "plt.figure()\n",
    "plt.loglog(x, y)\n",
    "plt.xlabel('stress_xy drop')\n",
    "plt.ylabel('PDF(stress_xy drop)')\n",
    "\n",
    "increments = np.hstack([d['increments'] for d in data])\n",
    "x, y = make_histogram(increments,log=True,nbins=40, filter_zeros=True)\n",
    "plt.figure()\n",
    "plt.loglog(x, y)\n",
    "plt.xlabel('stress_xy increment')\n",
    "plt.ylabel('PDF(stress_xy increment)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local mesoscale response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we analyze the local patch response. For that, we use the datasets that contain the results of the local shear tests located at `/snapshots/patches` within the output H5 files hierarchy. The tests are applied to patches extracted from different locations, with different shear orientations `alpha`, and on patches with different radii `R`. See the publication mentioned above for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_local_stress_df_meso(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Create the quantities of interest for the analysis based on the raw simulation results.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['ss_resolved'] = 0.5*(df['ss_11']-df['ss_00'])*np.sin(2*df['theta']*pi/180.) + df['ss_01']*np.cos(2*df['theta']*pi/180.)\n",
    "    df['oi_resolved'] = 0.5*(df['oi_11']-df['oi_00'])*np.sin(2*df['theta']*pi/180.) + df['oi_01']*np.cos(2*df['theta']*pi/180.)\n",
    "    df['ee_resolved'] = 0.5*(df['ee_11']-df['ee_00'])*np.sin(2*df['theta']*pi/180.) + df['ee_01']*np.cos(2*df['theta']*pi/180.)\n",
    "      \n",
    "    df['gamma'] = 2. * df['oi_eps']\n",
    "      \n",
    "    # to compute the local stress drop tensorial components, we rotate the tensors to have then in the system alingned with the \n",
    "    # applied shear test. In that case, when we compute the slip angle, we automatically have the difference between the \n",
    "    # angle of applied shear and the actual drop direction\n",
    "    a = df['theta']*pi/180\n",
    "    ee_01_ = 0.5*(df['ee_11']-df['ee_00'])*np.sin(2*a) + df['ee_01']*np.cos(2*a)  \n",
    "    ee_00_ = df['ee_00']*np.cos(a)**2 + df['ee_11']*np.sin(a)**2 + df['ee_01']*np.sin(2*a)\n",
    "    ee_11_ = df['ee_00']*np.sin(a)**2 + df['ee_11']*np.cos(a)**2 - df['ee_01']*np.sin(2*a)   \n",
    "    oi_01_ = 0.5*(df['oi_11']-df['oi_00'])*np.sin(2*a) + df['oi_01']*np.cos(2*a)  \n",
    "    oi_00_ = df['oi_00']*np.cos(a)**2 + df['oi_11']*np.sin(a)**2 + df['oi_01']*np.sin(2*a)\n",
    "    oi_11_ = df['oi_00']*np.sin(a)**2 + df['oi_11']*np.cos(a)**2 - df['oi_01']*np.sin(2*a)   \n",
    "      \n",
    "    drop_xx = oi_00_.values - ee_00_.values\n",
    "    drop_yy = oi_11_.values - ee_11_.values\n",
    "    drop_xy = oi_01_.values - ee_01_.values\n",
    "    df['slip_angle'] = 0.5*np.arctan2(-0.5*(drop_xx-drop_yy), drop_xy)*180/pi\n",
    "      \n",
    "    df = df.rename( columns={'ss_00':'nonrot_ss_pxx', 'ss_11':'nonrot_ss_pyy', 'ss_01':'nonrot_ss_pxy', \n",
    "                               'oi_00':'nonrot_oi_pxx', 'oi_11':'nonrot_oi_pyy', 'oi_01':'nonrot_oi_pxy', \n",
    "                               'ee_00':'nonrot_ee_pxx', 'ee_11':'nonrot_ee_pyy', 'ee_01':'nonrot_ee_pxy',  \n",
    "                               'theta': 'Alpha',\n",
    "                               'ref_element': 'PatchID'\n",
    "                               } )\n",
    "    df['resolved_shear'] = df['ss_resolved']\n",
    "    df['vm_stress'] = np.sqrt((0.5)*(0.5*np.power(df['nonrot_ss_pxx']-df['nonrot_ss_pyy'].values,2.)+2*np.power(df['nonrot_ss_pxy'],2.)))\n",
    "    df['dev_angle'] = 0.5*np.arctan2(-0.5*(df['nonrot_ss_pxx'].values-df['nonrot_ss_pyy'].values), df['nonrot_ss_pxy'].values)*180/pi\n",
    "    df['threshold'] = df['oi_resolved']\n",
    "    df['barrier'] = df['oi_resolved']-df['ss_resolved']\n",
    "    df['stress_drop'] = df['oi_resolved']-df['ee_resolved']\n",
    "    df['shear_modulus'] = df['barrier'] / df['gamma']\n",
    "    df['p_ss'] = -(df['nonrot_ss_pxx']+df['nonrot_ss_pyy'])/2. \n",
    "    df['p_threshold'] = -(df['nonrot_oi_pxx']+df['nonrot_oi_pyy'])/2. \n",
    "    df['p_barrier'] = df['p_threshold'] - df['p_ss']\n",
    "    df['p_drop'] = df['p_threshold'] - (-1)*(df['nonrot_ee_pxx']+df['nonrot_ee_pyy'])/2.\n",
    "    \n",
    "    df['Epot_el']  = df['ss_pe_el'] \n",
    "    df['Epot_conf']  = df['ss_pe_conf'] \n",
    "    df['Epot_total']  = df['ss_pe_el'] + df['ss_pe_conf']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meso_patch_stress(meso_filenames, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    This generator provides local stress data at the PATCH SCALE obtained from\n",
    "    mesoscale simulations by locally probing the system\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    eps0 = kwargs['eps0']\n",
    "    eps1 = kwargs['eps1']\n",
    "    N_patch_list =  kwargs['N_patch_list']\n",
    "    scale_factor = kwargs['scale_factor']\n",
    "\n",
    "    for filename in tqdm(meso_filenames):  \n",
    "\n",
    "        file = h5py.File(filename,'r') \n",
    "\n",
    "        T = file.attrs['temperature_liquid']\n",
    "            \n",
    "        try:\n",
    "            for group in file['snapshots/patches'].values():\n",
    "                assert(group.attrs['monitor_magnitude'].decode('UTF-8')=='total_strain')\n",
    "                snapshot_attrs = {k:v for k,v in group.attrs.items()}            \n",
    "                if snapshot_attrs['recorded_target'] >= eps0 and snapshot_attrs['recorded_target'] <= eps1 and snapshot_attrs['N_patch'] in N_patch_list:\n",
    "                    data = np.array(group)\n",
    "                    df = pd.DataFrame(data, columns=data.dtype.names)\n",
    "                    \n",
    "                    df = process_local_stress_df_meso(df)\n",
    "\n",
    "                    df['N_patch'] = snapshot_attrs['N_patch']\n",
    "                    \n",
    "                    # create a unique identifier for the samples\n",
    "                    seed = filename.split('/')[-1].split('seed_')[-1].split('.')[0]\n",
    "                    n_rep = group.name.split('_')[-1]\n",
    "                    df['sample'] = seed+'_'+n_rep\n",
    "\n",
    "                    df['R'] = df['N_patch'] * scale_factor\n",
    "                    df['T'] = T\n",
    "                    \n",
    "                    yield df\n",
    "                \n",
    "        except Exception as ex:\n",
    "            print('poblem with ', filename)\n",
    "            print(ex)\n",
    "            continue\n",
    "\n",
    "        file.close()\n",
    "\n",
    "    return        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = generate_meso_patch_stress(meso_filenames, eps0=0.5, eps1=5., N_patch_list=[1,2,4,8], scale_factor=7.5/2)\n",
    "data = list(data_generator)\n",
    "\n",
    "df = pd.concat(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local thresholds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "w = (df['Alpha']==0.)&(df['R']==30)\n",
    "x, y = make_histogram(df[w]['threshold'].values)\n",
    "plt.plot(x, y, label='0 deg')\n",
    "\n",
    "w = (df['Alpha']==90.)&(df['R']==30)\n",
    "x, y = make_histogram(df[w]['threshold'].values)\n",
    "plt.plot(x, y, label='90 deg')\n",
    "\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average threshold vs patch radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df.groupby(['R', 'Alpha'], as_index=False)['threshold'].mean()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "w = agg['Alpha']==0.\n",
    "x = agg[w]['R'].values\n",
    "y = agg[w]['threshold'].values\n",
    "plt.plot(x, y, label='0 deg')\n",
    "\n",
    "w = agg['Alpha']==90.\n",
    "x = agg[w]['R'].values\n",
    "y = agg[w]['threshold'].values\n",
    "plt.plot(x, y, label='90 deg')\n",
    "\n",
    "plt.gca().set_xscale('log')\n",
    "plt.xlabel('R')\n",
    "plt.ylabel('threshold_mean')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average threshold vs shear angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df[df['R']==30].groupby('Alpha', as_index=False)['threshold'].mean()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "x = agg['Alpha'].values\n",
    "y = agg['threshold'].values\n",
    "plt.plot(x, y, label='R = 30')\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('threshold_mean')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local barriers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF of barriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "w = (df['Alpha']==0.)&(df['R']==30)\n",
    "x, y = make_histogram(df[w]['barrier'].values)\n",
    "plt.loglog(x, y, label='0 deg')\n",
    "\n",
    "w = (df['Alpha']==90.)&(df['R']==30)\n",
    "x, y = make_histogram(df[w]['barrier'].values)\n",
    "plt.loglog(x, y, label='90 deg')\n",
    "\n",
    "plt.xlabel('barrier')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average barrier vs patch radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df.groupby(['R', 'Alpha'], as_index=False)['barrier'].mean()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "w = agg['Alpha']==0.\n",
    "x = agg[w]['R'].values\n",
    "y = agg[w]['barrier'].values\n",
    "plt.loglog(x, y, label='0 deg')\n",
    "\n",
    "w = agg['Alpha']==90.\n",
    "x = agg[w]['R'].values\n",
    "y = agg[w]['barrier'].values\n",
    "plt.loglog(x, y, label='90 deg')\n",
    "\n",
    "plt.gca().set_xscale('log')\n",
    "plt.xlabel('R')\n",
    "plt.ylabel('barrier_mean')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average barrier vs shear angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df[df['R']==30].groupby('Alpha', as_index=False)['barrier'].mean()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "x = agg['Alpha'].values\n",
    "y = agg['barrier'].values\n",
    "plt.plot(x, y, label='R = 30')\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('barrier_mean')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local stress drops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF of stress drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "w = (df['Alpha']==0.)&(df['R']==30)\n",
    "x, y = make_histogram(df[w]['stress_drop'].values)\n",
    "plt.loglog(x, y, label='0 deg')\n",
    "\n",
    "w = (df['Alpha']==90.)&(df['R']==30)\n",
    "x, y = make_histogram(df[w]['stress_drop'].values)\n",
    "plt.loglog(x, y, label='90 deg')\n",
    "\n",
    "plt.xlabel('stress_drop')\n",
    "plt.ylabel('PDF')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average stress drops vs patch radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df.groupby(['R', 'Alpha'], as_index=False)['stress_drop'].mean()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "w = agg['Alpha']==0.\n",
    "x = agg[w]['R'].values\n",
    "y = agg[w]['stress_drop'].values\n",
    "plt.loglog(x, y, label='0 deg')\n",
    "\n",
    "w = agg['Alpha']==90.\n",
    "x = agg[w]['R'].values\n",
    "y = agg[w]['stress_drop'].values\n",
    "plt.loglog(x, y, label='90 deg')\n",
    "\n",
    "plt.gca().set_xscale('log')\n",
    "plt.xlabel('R')\n",
    "plt.ylabel('stress_drop_mean')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average stress drops vs shear angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df[df['R']==30].groupby('Alpha', as_index=False)['stress_drop'].mean()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "x = agg['Alpha'].values\n",
    "y = agg['stress_drop'].values\n",
    "plt.plot(x, y, label='R = 30')\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('stress_drop_mean')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
